{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM\n",
    "    Hidden Markov Model\n",
    "\n",
    "[](https://www.cs.sjsu.edu/~stamp/RUA/HMM.pdf)\n",
    "\n",
    "## Notation\n",
    "    - A: state transition matrix\n",
    "    - B: observation probability / emission matrix\n",
    "    - O: observation sequence\n",
    "    - PI: initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([\n",
    "    [0.7, 0.3], \n",
    "    [0.4, 0.6]])\n",
    "B = np.array([\n",
    "    [0.1, 0.4, 0.5], \n",
    "    [0.7, 0.2, 0.1]])\n",
    "O = np.array([\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    2])\n",
    "PI = np.array([[0.6, 0.4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "    An Evaluation Problem\n",
    "\n",
    "### Description\n",
    "    given A,B,PI and O, compute p\n",
    "    \n",
    "### Solution\n",
    "    forward algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha \n",
      " [[0.06      0.28     ]\n",
      " [0.0616    0.0372   ]\n",
      " [0.0058    0.02856  ]\n",
      " [0.007742  0.0018876]] \n",
      "\n",
      "forward probability 0.009629599999999997\n"
     ]
    }
   ],
   "source": [
    "# 计算前向变量矩阵 alpha\n",
    "def forward(a,b,pi,o):\n",
    "    T = len(o)\n",
    "    N = a.shape[0]\n",
    "    alpha = np.zeros((T,N))\n",
    "    alpha[0] = pi * b[:, o[0]]\n",
    "#     print('initial alpha \\n', alpha, '\\n')\n",
    "    \n",
    "    for t in range(1,T):\n",
    "        alpha[t] = alpha[t-1].dot(a) * b[:, o[t]]\n",
    "#         print('alpha at step '+str(t) + '\\n', alpha, '\\n')\n",
    "    return alpha\n",
    "\n",
    "# marginalized likelihood\n",
    "def forward_probability(a,b,pi,o):\n",
    "    return forward(a,b,pi,o)[-1].sum()\n",
    "\n",
    "print('alpha \\n', forward(A,B,PI,O), '\\n')\n",
    "print('forward probability', forward_probability(A,B,PI,O))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "    Decoding / Prediction Problem\n",
    "\n",
    "### Description\n",
    "    given A,B,PI,O, find optimal state sequence\n",
    "    \n",
    "### Solution\n",
    "    viterbi algorithm,  a DP algorithm\n",
    "    should yield same result as that from brute force by compute p of all possible path with forward algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta\n",
      " [[0.06       0.28      ]\n",
      " [0.0448     0.0336    ]\n",
      " [0.003136   0.014112  ]\n",
      " [0.0028224  0.00084672]] \n",
      "\n",
      "psi\n",
      " [[0. 0.]\n",
      " [1. 1.]\n",
      " [0. 1.]\n",
      " [1. 1.]] \n",
      "\n",
      "viterbi\n",
      " [1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "def viterbi(a,b,pi,o):\n",
    "    T = len(o)\n",
    "    N = a.shape[0]\n",
    "    delta = np.zeros((T,N))\n",
    "    psi = np.zeros((T,N))\n",
    "    delta[0] = pi * b[:, o[0]]\n",
    "#     print('init delta\\n', delta, '\\n' )\n",
    "#     print('init psi\\n', psi, '\\n' )    \n",
    "    \n",
    "    for t in range(1,T):\n",
    "        for i in range(N):\n",
    "            delta[t,i] = np.max(delta[t-1]* a[:,i]) * b[i, o[t]] \n",
    "            psi[t,i] = np.argmax(delta[t-1]* a[:,i])\n",
    "#         print('step ' + str(t) + ' delta\\n', delta, '\\n' )\n",
    "#         print('step ' + str(t) + ' psi\\n', psi, '\\n' )\n",
    "    print('delta\\n', delta, '\\n' )\n",
    "    print('psi\\n', psi, '\\n' )    \n",
    "    \n",
    "    # backtrack\n",
    "    i_star = np.zeros(T,dtype=np.int32)\n",
    "    i_star[T-1] = np.argmax(delta[T-1])\n",
    "    for t in range(T-2,-1,-1): \n",
    "        i_star[t] = psi[t+1, i_star[t+1]]\n",
    "    \n",
    "    return i_star\n",
    "\n",
    "print('viterbi\\n', viterbi(A,B,PI,O))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second row of psi should be [1,1], which means that \n",
    "1. the best path of length two ending with 0 is 1->0 with p=0.0448\n",
    "2. the best path of length two ending with 1 is 1->1 with p=0.0336"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "    Learning Problem\n",
    "\n",
    "### Description\n",
    "    given O, total number of distinct states(A.shape), total number of distinct observations(B.shape), find optimal state sequence\n",
    "    \n",
    "### Solution\n",
    "    forward-backward algorithm, aka Baum-Welch algorithm\n",
    "    it is a particular case of EM(Expectation-Maximization) algorithm\n",
    "\n",
    "```\n",
    "Unsupervised training of a HMM involves running forward and backward to estimate the *expected* probability of taking various state sequences, then updates the model to match these *expectations*. This repeats many times until things stabilise (covergence). Note that it's non-convex, so the starting point often affects the converged solution. --from https://people.eng.unimelb.edu.au/tcohn/comp90042/HMM.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta \n",
      " [[0.0302  0.02792]\n",
      " [0.0812  0.1244 ]\n",
      " [0.38    0.26   ]\n",
      " [1.      1.     ]] \n",
      "\n",
      "backward probability \n",
      " 0.009629599999999999 \n",
      "\n",
      "should be equal to forward probability \n",
      " 0.009629599999999997 \n",
      "\n",
      "gamma \n",
      " [[0.18816981 0.81183019]\n",
      " [0.51943175 0.48056825]\n",
      " [0.22887763 0.77112237]\n",
      " [0.8039794  0.1960206 ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reuse forward function\n",
    "\n",
    "# 计算后向变量矩阵 beta\n",
    "def backward(a,b,pi,o):\n",
    "    T = len(o)\n",
    "    N = a.shape[0]\n",
    "    beta = np.zeros((T,N))\n",
    "    beta[-1:,:] = 1\n",
    "#     print('initial beta \\n', beta, '\\n') \n",
    "    \n",
    "    for t in range(T-2,-1,-1):\n",
    "        for i in range(N):\n",
    "            beta[t,i] = np.sum( a[i, :] * b[:, o[t+1]] * beta[t+1,:])\n",
    "#         print('beta at step '+str(T-t-1) + '\\n', beta, '\\n')\n",
    "\n",
    "    return beta\n",
    "\n",
    "# marginalized likelihood\n",
    "def backward_probability(a,b,pi,o):\n",
    "    beta = backward(a,b,pi,o)\n",
    "    return np.sum(pi * b[:,o[0]] * beta[0,:])\n",
    "\n",
    "# 计算 posterior probability\n",
    "# 每行 sum = 1\n",
    "def gamma(a,b,pi,o):\n",
    "    alpha = forward(a,b,pi,o)\n",
    "    beta = backward(a,b,pi,o)\n",
    "    p = alpha[-1].sum()\n",
    "    return np.multiply(alpha, beta) / p\n",
    "\n",
    "print('beta \\n', backward(A,B,PI,O), '\\n')\n",
    "print('backward probability \\n', backward_probability(A,B,PI,O), '\\n')\n",
    "print('should be equal to forward probability \\n', forward_probability(A,B,PI,O), '\\n')\n",
    "\n",
    "print('gamma \\n', gamma(A,B,PI,O), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
